{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 日志刷屏使我痛苦，我开发了VLog😋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练日志刷屏使我痛苦，我开发了VLog，可以在任意训练代码中轻松使用~\n",
    "\n",
    "例如，通过回调嵌入到lightgbm/catboost/transformers/ultralytics，乃至keras库的训练代码流程中~\n",
    "\n",
    "\n",
    "**before**:\n",
    "\n",
    "![](./data/before.png)\n",
    "\n",
    "\n",
    "\n",
    "**after**：\n",
    "\n",
    "![](./data/torchkeras_plot.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**为什么不用tensorboard或者wandb?**\n",
    "\n",
    "tensorboard需要开端口权限，服务器开发环境有时候没有端口权限~\n",
    "\n",
    "wandb需要联网，有时候网速很差或者没有网，影响体验~\n",
    "\n",
    "综合对比考虑如下表\n",
    "\n",
    "|日志方案    | 学习成本|  指标直观性 |是否需要端口权限|是否需要联网 |推荐星级|\n",
    "|:---------|:------:|:-------------:|:---------:|:---------:|:-----|\n",
    "|print      | 无需学习 |不直观,易刷屏|不需要    |不需要     |⭐️|\n",
    "|tensorboard| 较难学习 |比较直观,跨页面      |需要       |不需要     |⭐️⭐️|\n",
    "|wandb      | 较好学习 |比较直观,跨页面      |不需要     |需要       |⭐️⭐️⭐️⭐️|\n",
    "|VLog😋     | 极易学习 |非常直观,同页面      |不需要     |不需要      |⭐️⭐️⭐️⭐️⭐️|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U lightgbm \n",
    "#!pip install ultralytics\n",
    "#!pip install git+https://github.com/lyhue1991/torchkeras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一，VLog基本原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VLog类主要有以下5个方法。\n",
    "\n",
    "```python\n",
    "\n",
    "from torchkeras import VLog\n",
    "\n",
    "#1, 初始化方法\n",
    "vlog = VLog(epochs=20, monitor_metric='val_loss', monitor_mode='min') \n",
    "\n",
    "#2, 显示开始空图表\n",
    "vlog.log_start()\n",
    "\n",
    "#3, 更新step级别日志\n",
    "vlog.log_step({'train_loss':0.003,'val_loss':0.002}) \n",
    "\n",
    "#4, 更新epoch级别日志\n",
    "vlog.log_epoch({'train_acc':0.9,'val_acc':0.87,'train_loss':0.002,'val_loss':0.03})\n",
    "\n",
    "#5, 输出最终稳定状态图表\n",
    "vlog.log_end()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math,random\n",
    "from torchkeras import VLog\n",
    "\n",
    "epochs = 10\n",
    "batchs = 30\n",
    "\n",
    "#0, 指定监控北极星指标，以及指标优化方向\n",
    "vlog = VLog(epochs, monitor_metric='val_loss', monitor_mode='min') \n",
    "\n",
    "#1, log_start 初始化动态图表\n",
    "vlog.log_start() \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #train\n",
    "    for step in range(batchs):\n",
    "        \n",
    "        #2, log_step 更新step级别日志信息，打日志，并用小进度条显示进度\n",
    "        vlog.log_step({'train_loss':100-2.5*epoch+math.sin(2*step/batchs)}) \n",
    "        time.sleep(0.05)\n",
    "        \n",
    "    #eval    \n",
    "    for step in range(20):\n",
    "        \n",
    "        #3, log_step 更新step级别日志信息，指定training=False说明在验证模式，只打日志不更新小进度条\n",
    "        vlog.log_step({'val_loss':100-2*epoch+math.sin(2*step/batchs)},training=False)\n",
    "        time.sleep(0.05)\n",
    "        \n",
    "    #4, log_epoch 更新epoch级别日志信息，每个epoch刷新一次动态图表和大进度条进度\n",
    "    vlog.log_epoch({'val_loss':100 - 2*epoch+2*random.random()-1,\n",
    "                    'train_loss':100-2.5*epoch+2*random.random()-1})  \n",
    "\n",
    "# 5, log_end 调整坐标轴范围，输出最终指标可视化图表\n",
    "vlog.log_end()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二，在LightGBM中使用VLog "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设计一个简单的回调，就可以搞定~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras import VLog\n",
    "class VLogCallback:\n",
    "    def __init__(self, num_boost_round, \n",
    "                 monitor_metric='val_loss',\n",
    "                 monitor_mode='min'):\n",
    "        self.order = 20\n",
    "        self.num_boost_round = num_boost_round\n",
    "        self.vlog = VLog(epochs = num_boost_round, monitor_metric = monitor_metric, \n",
    "                         monitor_mode = monitor_mode)\n",
    "\n",
    "    def __call__(self, env) -> None:\n",
    "        metrics = {}\n",
    "        for item in env.evaluation_result_list:\n",
    "            if len(item) == 4:\n",
    "                data_name, eval_name, result = item[:3]\n",
    "                metrics[data_name+'_'+eval_name] = result\n",
    "            else:\n",
    "                data_name, eval_name = item[1].split()\n",
    "                res_mean = item[2]\n",
    "                res_stdv = item[4]\n",
    "                metrics[data_name+'_'+eval_name] = res_mean\n",
    "        self.vlog.log_epoch(metrics)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "    print(info+'...\\n\\n')\n",
    "\n",
    "#================================================================================\n",
    "# 一，读取数据\n",
    "#================================================================================\n",
    "printlog(\"step1: reading data...\")\n",
    "\n",
    "# 读取dftrain,dftest\n",
    "breast = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(breast.data,columns = [x.replace(' ','_') for x in breast.feature_names])\n",
    "df['label'] = breast.target\n",
    "df['mean_radius'] = df['mean_radius'].apply(lambda x:int(x))\n",
    "df['mean_texture'] = df['mean_texture'].apply(lambda x:int(x))\n",
    "dftrain,dftest = train_test_split(df)\n",
    "\n",
    "categorical_features = ['mean_radius','mean_texture']\n",
    "lgb_train = lgb.Dataset(dftrain.drop(['label'],axis = 1),label=dftrain['label'],\n",
    "                        categorical_feature = categorical_features)\n",
    "\n",
    "lgb_valid = lgb.Dataset(dftest.drop(['label'],axis = 1),label=dftest['label'],\n",
    "                        categorical_feature = categorical_features,\n",
    "                        reference=lgb_train)\n",
    "\n",
    "#================================================================================\n",
    "# 二，设置参数\n",
    "#================================================================================\n",
    "printlog(\"step2: setting parameters...\")\n",
    "                               \n",
    "boost_round = 50                   \n",
    "early_stop_rounds = 10\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective':'binary',\n",
    "    'metric': ['auc'], #'l2'\n",
    "    'num_leaves': 15,   \n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "    'early_stopping_round':5\n",
    "}\n",
    "\n",
    "#================================================================================\n",
    "# 三，训练模型\n",
    "#================================================================================\n",
    "printlog(\"step3: training model...\")\n",
    "\n",
    "result = {}\n",
    "\n",
    "vlog_cb = VLogCallback(boost_round, monitor_metric = 'val_auc', monitor_mode = 'max')\n",
    "vlog_cb.vlog.log_start()\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round= boost_round,\n",
    "                valid_sets=(lgb_valid, lgb_train),\n",
    "                valid_names=('val','train'),\n",
    "                callbacks = [lgb.record_evaluation(result),\n",
    "                             vlog_cb]\n",
    "               )\n",
    "\n",
    "vlog_cb.vlog.log_end()\n",
    "\n",
    "#================================================================================\n",
    "# 四，评估模型\n",
    "#================================================================================\n",
    "printlog(\"step4: evaluating model ...\")\n",
    "\n",
    "y_pred_train = gbm.predict(dftrain.drop('label',axis = 1), num_iteration=gbm.best_iteration)\n",
    "y_pred_test = gbm.predict(dftest.drop('label',axis = 1), num_iteration=gbm.best_iteration)\n",
    "\n",
    "print('train accuracy: {:.5} '.format(accuracy_score(dftrain['label'],y_pred_train>0.5)))\n",
    "print('valid accuracy: {:.5} \\n'.format(accuracy_score(dftest['label'],y_pred_test>0.5)))\n",
    "\n",
    "\n",
    "#================================================================================\n",
    "# 五，保存模型\n",
    "#================================================================================\n",
    "printlog(\"step5: saving model ...\")\n",
    "\n",
    "\n",
    "model_dir = \"gbm.model\"\n",
    "print(\"model_dir: %s\"%model_dir)\n",
    "gbm.save_model(\"gbm.model\")\n",
    "printlog(\"task end...\")\n",
    "\n",
    "###\n",
    "##\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三， 在ultralytics中使用VLog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "写个适配的回调~\n",
    "\n",
    "ultralytics可以做 分类，检测，分割 等等。\n",
    "\n",
    "这个回调函数是通用的，此处以分类问题为例，改个monitor_metric即可~\n",
    "\n",
    "\n",
    "cats_vs_dogs数据集可以在公众号算法美食屋后台回复:**torchkeras** 获取~ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras import VLog\n",
    "class VLogCallback:\n",
    "    def __init__(self,epochs,monitor_metric,monitor_mode):\n",
    "        self.vlog = VLog(epochs,monitor_metric,monitor_mode)\n",
    "        \n",
    "    def on_train_batch_end(self,trainer):\n",
    "        self.vlog.log_step(trainer.label_loss_items(trainer.tloss, prefix='train'))\n",
    "\n",
    "    def on_fit_epoch_end(self,trainer):\n",
    "        metrics = {k.split('/')[-1]:v for k,v in trainer.metrics.items() if 'loss' not in k}\n",
    "        self.vlog.log_epoch(metrics)\n",
    "\n",
    "    def on_train_epoch_end(self,trainer):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO \n",
    "epochs = 10\n",
    "\n",
    "vlog_cb = VLogCallback(epochs = epochs,\n",
    "                       monitor_metric='accuracy_top1',\n",
    "                       monitor_mode='max')\n",
    "callbacks = {\n",
    "    \"on_train_batch_end\": vlog_cb.on_train_batch_end,\n",
    "    \"on_fit_epoch_end\": vlog_cb.on_fit_epoch_end\n",
    "}\n",
    "\n",
    "model = YOLO(model = 'yolov8n-cls.pt')\n",
    "for event,func in callbacks.items():\n",
    "    model.add_callback(event,func)\n",
    "    \n",
    "vlog_cb.vlog.log_start()\n",
    "results = model.train(data='cats_vs_dogs', \n",
    "                      epochs=epochs, workers=4)     # train the model\n",
    "vlog_cb.vlog.log_end()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四， 在transformers中使用VLog "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "waimai评论数据集可以在公众号算法美食屋后台回复:**torchkeras** 获取~ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#回调给你写好了~\n",
    "from torchkeras.tools.transformers import VLogCallback "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch \n",
    "import datasets \n",
    "from transformers import AutoTokenizer,DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification \n",
    "from transformers import TrainingArguments,Trainer \n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "from tqdm import tqdm \n",
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "\n",
    "#一，准备数据\n",
    "\n",
    "df = pd.read_csv(\"waimai_10k.csv\")\n",
    "ds = datasets.Dataset.from_pandas(df)\n",
    "ds = ds.shuffle(42) \n",
    "ds = ds.rename_columns({\"review\":\"text\",\"label\":\"labels\"})\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-chinese') \n",
    "\n",
    "ds_encoded = ds.map(lambda example:tokenizer(example[\"text\"]),\n",
    "                    remove_columns = [\"text\"],\n",
    "                    batched=True)\n",
    "\n",
    "#train,val,test split\n",
    "ds_train_val,ds_test = ds_encoded.train_test_split(test_size=0.2).values()\n",
    "ds_train,ds_val = ds_train_val.train_test_split(test_size=0.2).values() \n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=16, collate_fn = data_collator)\n",
    "dl_val = torch.utils.data.DataLoader(ds_val, batch_size=16,  collate_fn = data_collator)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=16,  collate_fn = data_collator)\n",
    "\n",
    "for batch in dl_train:\n",
    "    break\n",
    "print({k: v.shape for k, v in batch.items()})\n",
    "\n",
    "\n",
    "\n",
    "#二，定义模型\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'bert-base-chinese',num_labels=2)\n",
    "\n",
    "#三，训练模型\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    accuracy = np.sum(preds==labels)/len(labels)\n",
    "    precision = np.sum((preds==1)&(labels==1))/np.sum(preds==1)\n",
    "    recall = np.sum((preds==1)&(labels==1))/np.sum(labels==1)\n",
    "    f1  = 2*recall*precision/(recall+precision)\n",
    "    return {\"accuracy\":accuracy,\"precision\":precision,\"recall\":recall,'f1':f1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"bert_waimai\",\n",
    "    num_train_epochs = 3,\n",
    "    logging_steps = 20,\n",
    "    gradient_accumulation_steps = 10,\n",
    "    evaluation_strategy=\"steps\", #epoch\n",
    "    \n",
    "    metric_for_best_model='eval_f1',\n",
    "    greater_is_better=True,\n",
    "    \n",
    "    report_to='none',\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "callbacks = [EarlyStoppingCallback(early_stopping_patience=10),\n",
    "             VLogCallback()] #监控指标同 metric_for_best_model\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_val,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = callbacks,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train() \n",
    "\n",
    "\n",
    "\n",
    "#四，评估模型\n",
    "trainer.evaluate(ds_val)\n",
    "\n",
    "\n",
    "#五，使用模型\n",
    "from transformers import pipeline\n",
    "model.config.id2label = {0:\"差评\",1:\"好评\"}\n",
    "classifier = pipeline(task=\"text-classification\",tokenizer = tokenizer,model=model.cpu())\n",
    "classifier(\"挺好吃的哦\")\n",
    "\n",
    "#六，保存模型\n",
    "model.save_pretrained(\"waimai_10k_bert\")\n",
    "tokenizer.save_pretrained(\"waimai_10k_bert\")\n",
    "\n",
    "classifier = pipeline(\"text-classification\",model=\"waimai_10k_bert\")\n",
    "classifier([\"味道还不错，下次再来\",\"我去，吃了我吐了三天\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**如果本项目对你有所帮助，想鼓励一下作者，记得给本项目加一颗星星star⭐️，并分享给你的朋友们喔😊!** \n",
    "\n",
    "如果在torchkeras的使用中遇到问题，可以在项目中提交issue。\n",
    "\n",
    "如果想要获得更快的反馈或者与其他torchkeras用户小伙伴进行交流，\n",
    "\n",
    "可以在公众号算法美食屋后台回复关键字：**加群**。\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
